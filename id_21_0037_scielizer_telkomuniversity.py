# -*- coding: utf-8 -*-
"""ID-21-0037_Scielizer_TelkomUniversity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z7sPtNgxy0AdTF-XEKzKg-aLzs1R9kWy

#### Import Required Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from scipy import stats 

from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn import preprocessing
from sklearn.preprocessing import  MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier

"""### Data Exploration and Data Cleansing

#### Read and Analyze Data
"""

# read csv file using pandas where stored in my github 
test = pd.read_csv('https://raw.githubusercontent.com/FarhanLhant/lomba_dataset/main/Test.csv', index_col=0)
train = pd.read_csv('https://raw.githubusercontent.com/FarhanLhant/lomba_dataset/master/Train.csv', index_col=0)
train.head()

# Dropping some column 
train = train.drop(['time_date', 'buying_date', 'dealing_date', 'site','dealing'], axis=1)
test = test.drop(['time_date', 'buying_date', 'dealing_date', 'site'], axis=1)

# Checking duplicate data
duplicateRowsDF = train[train.duplicated(keep='last')]
print(duplicateRowsDF)

# Remove duplicate data
train.drop_duplicates(keep=False,inplace=True)

"""#### Analyzing Label Ratio on Dataset using piechart"""

a = train['regency_cluster'].value_counts()

plot = a.plot.pie(figsize=(15, 15))

"""#### Cleansing Data"""

#Check for null value in data
train.isnull().sum()

train['distance'] = train['distance'].fillna(train['distance'].mean())
test['distance'] = test['distance'].fillna(train['distance'].mean())

"""#### Data Preprocessing"""

# Normalize Data With MinMax Scaling Method
scaler = MinMaxScaler()
train[[ 'continent_id', 'buyer_country', 'buyer_region','buyer_city', 'distance', 'buyer_id', 'mobile', 'package','channel_id', 'adults', 'children', 'room', 'destination_id', 'destination_type','regency_continent', 'regency_country', 'regency_market', 'cnt']] = scaler.fit_transform(train[
                                                            [ 'continent_id', 'buyer_country', 'buyer_region','buyer_city', 'distance', 'buyer_id', 'mobile', 'package','channel_id', 'adults', 'children', 'room', 'destination_id', 'destination_type', 'regency_continent', 'regency_country', 'regency_market', 'cnt']])
test[[ 'continent_id', 'buyer_country', 'buyer_region','buyer_city', 'distance', 'buyer_id', 'mobile', 'package','channel_id', 'adults', 'children', 'room', 'destination_id', 'destination_type','regency_continent', 'regency_country', 'regency_market']] = scaler.fit_transform(test[
                                                            [ 'continent_id', 'buyer_country', 'buyer_region','buyer_city', 'distance', 'buyer_id', 'mobile', 'package','channel_id', 'adults', 'children', 'room', 'destination_id', 'destination_type', 'regency_continent', 'regency_country', 'regency_market']])

# Separating Attributes and Labels on Datasets
attribute= train[[ 'continent_id', 'buyer_country', 'buyer_region','buyer_city', 'distance', 'buyer_id', 'mobile', 'package','channel_id', 'adults', 'children', 'room', 'destination_id', 'destination_type', 'regency_continent', 'regency_country', 'regency_market', 'cnt']]
label = train['regency_cluster']

"""###Splitting Data"""

# Split Data Into Train and Test using Pareto Principle
X_train, X_test, y_train, y_test = train_test_split(attribute , label, test_size=0.8, random_state=1)

"""### Implementing Machine Learning Model PCA + Logistic Regression and PCA + Decision Tree Model """

pca = PCA(n_components=0.95)
pca.fit(X_train)
reduced = pca.transform(X_train)

plt.rcParams["figure.figsize"] = (12,6)

fig, ax = plt.subplots()
xi = np.arange(1, 14, step=1)
y = np.cumsum(pca.explained_variance_ratio_)


plt.ylim(0.0,1.1)
plt.plot(xi, y, marker='o', linestyle='--', color='b')

plt.xlabel('Number of Components')
plt.xticks(np.arange(0, 15, step=1)) #change from 0-based array index to 1-based human-readable label
plt.ylabel('Cumulative variance (%)')
plt.title('The number of components needed to explain variance')

plt.axhline(y=0.95, color='r', linestyle='-')
plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)

ax.grid(axis='x')
plt.show()

pca = PCA(n_components=12)
Y = y_train
train1 = X_train
X = pca.fit_transform(train1)
test1 = pca.fit_transform(test)

"""####Logistic Regression"""

logreg = LogisticRegression()
logreg.fit(X, Y)
Ypred_Logistic = logreg.predict(test1)
acc_log = logreg.score(X,Y)
print(acc_log)

"""####Decision Tree"""

decision_tree = DecisionTreeClassifier()
decision_tree.fit(X,Y)
Ypred_Tree = decision_tree.predict(test1).astype(int)
acc_decision_tree = decision_tree.score(X,Y) 
print(acc_decision_tree)

"""####Model Comparison"""

comparison = {'Model': ['Logistic Regression', 'Decision Tree'],\
              'Accuracy': [0.049917,0.944612]}
pd.DataFrame.from_dict(comparison)

"""### Evaluation Model

#### Removing Outliers
"""

# Definisikan nilai Z score
z = np.abs(stats.zscore(train))
train2 = train[(z < 3).all(axis=1)]

attribute2= train2[[ 'continent_id', 'buyer_country', 'buyer_region','buyer_city', 'distance', 'buyer_id', 'mobile', 'package','channel_id', 'adults', 'children', 'room', 'destination_id', 'destination_type', 'regency_continent', 'regency_country', 'regency_market', 'cnt']]
label2 = train2['regency_cluster']

from sklearn.model_selection import train_test_split
# Split Data Into Train and Test
X_train2, X_test2, y_train2, y_test2 = train_test_split(attribute2 , label2, test_size=0.8, random_state=1)

pca = PCA(n_components=12)
Y2 = y_train2
train2 = X_train2
X2 = pca.fit_transform(train2)
test2 = pca.fit_transform(test)

decision_tree = DecisionTreeClassifier()
decision_tree.fit(X2,Y2)
Ypred_Tree_wo = decision_tree.predict(test2).astype(int)
acc_decision_tree = decision_tree.score(X2,Y2) 
print(acc_decision_tree)

"""#### Decision Tree Model Comparison"""

comparison_tree = {'Model': ['Model Decision Tree 1 - using outliers', 'Model Decision Tree 2 - without outliers'],\
              'Accuracy': [0.9446116919572027, 0.9395184967704052]
              }
pd.DataFrame.from_dict(comparison_tree)

"""#### Cross validation"""

pca = PCA(n_components=12)
Y = y_test
train1 = X_test
X = pca.fit_transform(train1)
test1 = pca.fit_transform(test)

decision_tree = DecisionTreeClassifier()
decision_tree.fit(X,Y)
Ypred_Tree_cro = decision_tree.predict(test1).astype(int)
acc_decision_tree = decision_tree.score(X,Y) 
print(acc_decision_tree)

"""### Evaluation Result Test"""

data = pd.read_csv('https://raw.githubusercontent.com/FarhanLhant/lomba_dataset/main/Test.csv')
output = data.loc[:,['id']]
output['regency_cluster']=Ypred_Tree[:]
output.to_csv('ID-21-0037_Scielizer_TelkomUniversity.csv',index=False)